"""
Tests for the mode-based quote generation system.

Tests the CALC, PRICE, and TABLE modes with their schemas,
tool gating, and mode inference logic.
"""

from unittest.mock import patch

from django.test import TestCase
from django.utils import timezone
from jsonschema import ValidationError

from apps.client.models import Client
from apps.job.models import Job
from apps.job.schemas import quote_mode_schemas
from apps.job.services.quote_mode_controller import QuoteModeController
from apps.testing import BaseTestCase


class TestQuoteModeSchemas(TestCase):
    """Test the JSON schemas for each mode."""

    def test_calc_schema_valid(self):
        """Test valid CALC schema data."""
        valid_data = {
            "inputs": {
                "raw_input": "3 boxes 700x700x400mm",
                "parsed": "dimensions: 700x700x400, qty: 3",
            },
            "results": {
                "items": [
                    {
                        "description": "Flat pattern for box",
                        "quantity": 2800,
                        "unit": "mm x mm",
                        "specs": "material: 304, thickness: 0.8mm",
                    }
                ],
                "assumptions": "Open top box, 0.8mm 304 stainless steel",
            },
            "questions": [],
        }

        schema = quote_mode_schemas.get_schema("CALC")
        # Should not raise ValidationError
        from jsonschema import validate

        validate(instance=valid_data, schema=schema)

    def test_calc_schema_invalid_missing_required(self):
        """Test CALC schema validation with missing required fields."""
        invalid_data = {
            "inputs": {"units": "mm"},
            # Missing results and questions
        }

        schema = quote_mode_schemas.get_schema("CALC")
        from jsonschema import validate

        with self.assertRaises(ValidationError):
            validate(instance=invalid_data, schema=schema)

    def test_price_schema_valid(self):
        """Test valid PRICE schema data."""
        valid_data = {
            "normalized": {
                "family": "stainless",
                "grade": "304",
                "thickness_mm": 0.9,
                "form": "sheet",
                "sheet_size_mm": [1220, 2440],
                "qty_uom": "sheet",
                "qty_required": 3,
            },
            "candidates": [
                {
                    "supplier": "XYZ Metals",
                    "sku": "SS304-0.9-1220x2440",
                    "uom": "sheet",
                    "price_per_uom": 189.00,
                    "lead_time_days": 2,
                    "delivery": 25.00,
                    "notes": "BA finish",
                }
            ],
            "questions": [],
        }

        schema = quote_mode_schemas.get_schema("PRICE")
        from jsonschema import validate

        validate(instance=valid_data, schema=schema)

    def test_table_schema_valid(self):
        """Test valid TABLE schema data."""
        valid_data = {
            "rows": [
                {
                    "item": "SS304 Sheet",
                    "qty": 3,
                    "uom": "sheet",
                    "unit_cost": 189.00,
                    "subtotal": 567.00,
                }
            ],
            "totals": {
                "material": 567.00,
                "labour": 235.40,
                "freight": 25.00,
                "overheads": 28.00,
                "markup_pct": 15,
                "grand_total_ex_gst": 983.71,
            },
            "markdown": "| Item | Qty | Unit | Cost |\n|------|-----|------|------|\n",
            "questions": [],
        }

        schema = quote_mode_schemas.get_schema("TABLE")
        from jsonschema import validate

        validate(instance=valid_data, schema=schema)

    def test_get_allowed_tools(self):
        """Test tool gating for each mode."""
        # CALC mode should have sheet tenths tool and emit tool
        calc_tools = quote_mode_schemas.get_allowed_tools("CALC")
        self.assertEqual(calc_tools, ["calc_sheet_tenths", "emit_calc_result"])

        # PRICE mode should have pricing tools plus emit tool
        price_tools = quote_mode_schemas.get_allowed_tools("PRICE")
        self.assertIn("search_products", price_tools)
        self.assertIn("get_pricing_for_material", price_tools)
        self.assertIn("compare_suppliers", price_tools)
        self.assertIn("emit_price_result", price_tools)

        # TABLE mode should have only emit tool
        table_tools = quote_mode_schemas.get_allowed_tools("TABLE")
        self.assertEqual(table_tools, ["emit_table_result"])


class TestQuoteModeController(BaseTestCase):
    """Test the QuoteModeController functionality."""

    def setUp(self):
        """Set up test fixtures."""
        self.controller = QuoteModeController()

        # Create test job
        self.client_obj = Client.objects.create(
            name="Test Client",
            email="test@example.com",
            xero_last_modified=timezone.now(),
        )
        self.job = Job.objects.create(
            name="Test Job",
            client=self.client_obj,
        )

    @patch("apps.job.services.quote_mode_controller.LLMService")
    def test_mode_inference_calc(self, mock_llm_class):
        """Test mode inference for CALC-related inputs.

        Uses mocked LLM responses captured from real API calls.
        """
        # Mock LLMService to return CALC for calculation-related inputs
        mock_llm = mock_llm_class.return_value
        mock_llm.get_text_response.return_value = "CALC"

        test_inputs = [
            "Calculate the area for 100x50mm parts",
            "How many sheets do I need for 20 parts?",
            "What's the yield for nesting these dimensions?",
            "Calculate sheet requirements with 0.2mm kerf",
        ]

        for input_text in test_inputs:
            mode = self.controller.infer_mode(input_text)
            self.assertEqual(mode, "CALC", f"Failed to infer CALC for: {input_text}")

    @patch("apps.job.services.quote_mode_controller.LLMService")
    def test_mode_inference_price(self, mock_llm_class):
        """Test mode inference for PRICE-related inputs.

        Uses mocked LLM responses captured from real API calls.
        """
        # Mock LLMService to return PRICE for pricing-related inputs
        mock_llm = mock_llm_class.return_value
        mock_llm.get_text_response.return_value = "PRICE"

        test_inputs = [
            "What's the price for 304 stainless?",
            "Find suppliers for aluminum sheet",
            "Get pricing for steel angle",
            "Compare costs from different suppliers",
        ]

        for input_text in test_inputs:
            mode = self.controller.infer_mode(input_text)
            self.assertEqual(mode, "PRICE", f"Failed to infer PRICE for: {input_text}")

    @patch("apps.job.services.quote_mode_controller.LLMService")
    def test_mode_inference_table(self, mock_llm_class):
        """Test mode inference for TABLE-related inputs.

        Uses mocked LLM responses captured from real API calls.
        """
        # Mock LLMService to return TABLE for summary-related inputs
        mock_llm = mock_llm_class.return_value
        mock_llm.get_text_response.return_value = "TABLE"

        test_inputs = [
            "Generate the final quote table",
            "Show me the summary",
            "What's the grand total?",
            "Create invoice breakdown",
        ]

        for input_text in test_inputs:
            mode = self.controller.infer_mode(input_text)
            self.assertEqual(mode, "TABLE", f"Failed to infer TABLE for: {input_text}")

    def test_system_prompt(self):
        """Test that system prompt is appropriate for mode-based operation."""
        prompt = self.controller.get_system_prompt()

        # Check for key mode-related instructions
        self.assertIn("MODE=CALC", prompt)
        self.assertIn("MODE=PRICE", prompt)
        self.assertIn("MODE=TABLE", prompt)
        self.assertIn("emit_calc_result", prompt)
        self.assertIn("emit_price_result", prompt)
        self.assertIn("emit_table_result", prompt)
        self.assertIn("MUST call", prompt)

    def test_render_prompt(self):
        """Test prompt rendering for each mode."""
        # Test CALC prompt
        calc_prompt = self.controller.render_prompt(
            mode="CALC",
            user_input="Calculate area for 100x50mm",
            job_ctx={"job_number": "TEST001", "client": "Test Client"},
        )
        self.assertIn("MODE=CALC", calc_prompt)
        self.assertIn("SCHEMA for CALC", calc_prompt)
        self.assertIn("TEST001", calc_prompt)

        # Test PRICE prompt
        price_prompt = self.controller.render_prompt(
            mode="PRICE", user_input="Price 304 stainless", job_ctx=None
        )
        self.assertIn("MODE=PRICE", price_prompt)
        self.assertIn("emit_price_result", price_prompt)

        # Test TABLE prompt
        table_prompt = self.controller.render_prompt(
            mode="TABLE", user_input="Generate summary", job_ctx=None
        )
        self.assertIn("MODE=TABLE", table_prompt)
        self.assertIn("emit_table_result", table_prompt)

    def test_validate_json(self):
        """Test JSON validation against schemas."""
        # Valid data should pass
        valid_calc_data = {
            "inputs": {"raw_input": "test input", "parsed": "test parsed input"},
            "results": {
                "items": [{"description": "Test item", "quantity": 1, "unit": "each"}],
                "assumptions": "Test assumptions",
            },
            "questions": ["What are the dimensions?"],
        }
        validated = self.controller.validate_json(
            valid_calc_data, self.controller.schemas["CALC"]
        )
        self.assertEqual(validated, valid_calc_data)

        # Invalid data should raise ValidationError
        invalid_data = {"wrong": "structure"}
        with self.assertRaises(ValidationError):
            self.controller.validate_json(invalid_data, self.controller.schemas["CALC"])

    def test_get_mcp_tools_for_mode(self):
        """Test that correct tools are returned for each mode."""
        # CALC mode - calc_sheet_tenths and emit tool
        calc_tools = self.controller.get_mcp_tools_for_mode("CALC")
        self.assertEqual(len(calc_tools), 2)
        tool_names = [t["function"]["name"] for t in calc_tools]
        self.assertIn("calc_sheet_tenths", tool_names)
        self.assertIn("emit_calc_result", tool_names)

        # PRICE mode - pricing tools plus emit tool
        price_tools = self.controller.get_mcp_tools_for_mode("PRICE")
        self.assertEqual(len(price_tools), 4)  # 3 search tools + 1 emit tool
        tool_names = [t["function"]["name"] for t in price_tools]
        self.assertIn("search_products", tool_names)
        self.assertIn("get_pricing_for_material", tool_names)
        self.assertIn("compare_suppliers", tool_names)
        self.assertIn("emit_price_result", tool_names)

        # TABLE mode - only emit tool
        table_tools = self.controller.get_mcp_tools_for_mode("TABLE")
        self.assertEqual(len(table_tools), 1)
        self.assertEqual(table_tools[0]["function"]["name"], "emit_table_result")

    def test_invalid_mode(self):
        """Test that invalid mode raises ValueError."""
        with self.assertRaises(ValueError) as context:
            self.controller.run(mode="INVALID", user_input="Test", job=None)
        self.assertIn("Invalid mode", str(context.exception))


class TestSheetTenthsIntegration(BaseTestCase):
    """Integration tests for sheet tenths calculation in CALC mode."""

    def setUp(self):
        """Set up test fixtures."""
        # Create test job
        self.client_obj = Client.objects.create(
            name="Test Client",
            email="test@example.com",
            xero_last_modified=timezone.now(),
        )
        self.job = Job.objects.create(
            name="Sheet Tenths Test Job",
            client=self.client_obj,
        )

    @patch("apps.job.services.chat_service.ChatService.generate_mode_response")
    def test_calc_mode_sheet_tenths_700x700(self, mock_generate_mode_response):
        """
        Test sheet tenths calculation response format.

        Uses mocked response captured from real LLM API call.
        The captured response shows:
        - LLM correctly calls calc_sheet_tenths tool
        - Result correctly shows 4 tenths for 700x700mm part
        """
        from apps.job.models import JobQuoteChat
        from apps.job.services.chat_service import ChatService

        # Create mock response with real captured data
        mock_response = JobQuoteChat(
            job=self.job,
            message_id="mock-calc-response",
            role="assistant",
            content=(
                "**Calculation Results:**\n\n"
                "* Items: [{'description': 'Sheet usage for 700x700mm part', "
                "'quantity': 4, 'unit': 'tenths', "
                "'specs': 'Part: 700mm x 700mm, Sheet: 1200mm x 2400mm standard'}]\n"
                "* Assumptions: Assumed standard sheet size of 1200mm x 2400mm, "
                "sheet divided into 5x2 grid (600mm x 480mm sections per tenth)"
            ),
            metadata={
                "mode": "CALC",
                "response_data": {
                    "inputs": {
                        "raw_input": "Calculate sheet usage for 700x700mm part",
                        "parsed": "Part dimensions: 700mm x 700mm, need to calculate sheet usage/tenths",
                    },
                    "results": {
                        "items": [
                            {
                                "description": "Sheet usage for 700x700mm part",
                                "quantity": 4,
                                "unit": "tenths",
                                "specs": "Part: 700mm x 700mm, Sheet: 1200mm x 2400mm standard",
                            }
                        ],
                        "assumptions": (
                            "Assumed standard sheet size of 1200mm x 2400mm, "
                            "sheet divided into 5x2 grid (600mm x 480mm sections per tenth)"
                        ),
                    },
                    "questions": [],
                },
                "has_questions": False,
                "model": "test-model",
                "user_message": "Calculate sheet usage for 700x700mm part",
            },
        )
        mock_generate_mode_response.return_value = mock_response

        # Run the test
        chat_service = ChatService()
        response = chat_service.generate_mode_response(
            job_id=str(self.job.id),
            user_message="Calculate sheet usage for 700x700mm part",
            mode="CALC",
        )

        # Verify response
        self.assertIsNotNone(response)
        self.assertEqual(response.role, "assistant")

        # Check that the response mentions 4 tenths
        content_lower = response.content.lower()
        self.assertTrue(
            "4" in content_lower and "tenth" in content_lower,
            f"Response should mention 4 tenths. Got: {response.content}",
        )

        # Check metadata structure
        self.assertIn("response_data", response.metadata)
        response_data = response.metadata["response_data"]
        self.assertIn("results", response_data)
        self.assertIn("items", response_data["results"])

        items = response_data["results"]["items"]
        self.assertGreater(len(items), 0)

        # Verify the 4 tenths result
        found_tenths = False
        for item in items:
            if "tenth" in item.get("unit", "").lower():
                self.assertEqual(
                    item["quantity"], 4, "700x700mm part should use 4 tenths"
                )
                found_tenths = True
                break
        self.assertTrue(found_tenths, "Should have tenths calculation in results")
